# 字符编码

<!--
create time: 2018-05-15 18:01:44
Author: <黄东鸿>
--> 

## bit 和 byte

* bit：比特或位，缩写是**小写的b**，是计算机二进制数据的最小计量单元，一个二进制数据的0或1，就是1bit
* byte：字节，缩写是**大写的B**，是计算机存储的最小单位，1 byte = 8 bits

这两个单位比较容易混淆，平时提到的 100Mbps 和 100MB，其实是两个不同的概念，前者指传输速率，后者指数据文件大小（存储空间容量）。

**一般情况下，只要涉及到数据传输速率的，一律以bit为单位，涉及到存储容量（数据文件大小）的一律以byte为单位**

除此之外，两者的换算机制也不一样。**数据传输速率的衡量单位K是十进制含义，而数据存储的K是2进制含义。**


    1 Byte（B）         = 8 bit
    1 Kilo Byte（KB）   = 1024 B
    1 Mega Byte（MB）   = 1024 KB
    1 Giga Byte （GB）  = 1024 MB
    1 Tera Byte（TB）   = 1024 GB
    1 Peta Byte（PB）   = 1024 TB
    1 Exa Byte（EB）    = 1024 PB
    1 Zetta Byte（ZB）  = 1024 EB
    1 Yotta Byte（YB）  = 1024 ZB
    1 Bronto Byte（BB） = 1024 YB
    1 Nona Byte（NB）   = 1024 BB
    1 Dogga Byte（DB）  = 1024 NB
    1 Corydon Byte（CB）= 1024 DB

    1 bps(bit per second) = 1 bit/s
    1 Kbps                = 1000 bit/s
    1 Mbps                = 1000 Kbps

平时我们说的网络带宽和网络下载速度也和我们想象中的不一样。

100M的带宽即指 100 Mbps = 1000 Kbps = 1000 / 8 KBps = 125 KBps。

所以100M的宽带的最高下载速度只有 125 KB 每秒。

## ASCII, Unicode, UTF-8

参考链接：
 
[字符编码笔记：ASCII，Unicode 和 UTF-8 -- 阮一峰](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)
 
[汉字究竟占几个字节？](https://www.rdhonor.com/archives/125.html)

延伸阅读：

[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)

[RFC3629：UTF-8, a transformation format of ISO 10646（如何实现UTF-8的规定）](https://www.ietf.org/rfc/rfc3629.txt)

[程序员趣味读物：谈谈Unicode编码](http://www.pconline.com.cn/pcedu/empolder/gj/other/0505/616631.html)

**英文字母和中文汉字在不同字符集编码下的字节数**

| 编码 | 字母字节数（bytes）| 汉字字节数（bytes）|
| :---: | :---: | :---: | :---: |
| GB2312 | 1 | 2 |
| GBK	| 1	| 2 |
| GB18030	| 1	| 2 |
| ISO-8859-1 | 1 | 1 |
| UTF-8	| 1	| 3 |
| UTF-16 | 4 | 4 |
| UTF-16BE | 2 | 2 | 
| UTF-16LE | 2 | 2 |

### 字符编码的历史

1. 美国人首先对其英文字符进行了编码，也就是最早的ascii码，用一个字节的低7位来表示英文的128个字符，高1位统一为0；
2. 后来欧洲人发现尼玛你这128位哪够用，比如我高贵的法国人字母上面的还有注音符，这个怎么区分，得，把高1位编进来吧，这样欧洲普遍使用一个全字节进行编码，最多可表示256位。欧美人就是喜欢直来直去，字符少，编码用得位数少；
3. 但是即使位数少，不同国家地区用不同的字符编码，虽然0—127表示的符号是一样的，但是128—255这一段的解释完全乱套了，即使2进制完全一样，表示的字符完全不一样，比如135在法语，希伯来语，俄语编码中完全是不同的符号；
4. 更麻烦的是，尼玛这电脑高科技传到中国后，中国人发现我们有10万多个汉字，你们欧美这256字塞牙缝都不够。于是就发明了GB2312这些汉字编码，典型的用2个字节来表示绝大部分的常用汉字，最多可以表示65536个汉字字符，这样就不难理解有些汉字你在新华字典里查得到，但是电脑上如果不处理一下你是显示不出来的了吧。
5. 这下各用各的字符集编码，这世界咋统一？俄国人发封email给中国人，两边字符集编码不同，尼玛显示都是乱码啊。为了统一，于是就发明了unicode，将世界上所有的符号都纳入其中，每一个符号都给予一个独一无二的编码，现在unicode可以容纳100多万个符号，每个符号的编码都不一样，这下可统一了，所有语言都可以互通，一个网页页面里可以同时显示各国文字。
6. 然而，unicode虽然统一了全世界字符的二进制编码，但没有规定如何存储啊，亲。x86和amd体系结构的电脑小端序和大端序都分不清，别提计算机如何识别到底是unicode还是acsii了。如果Unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，文本文件的大小会因此大出二三倍，这对于存储来说是极大的浪费。这样导致一个后果：出现了Unicode的多种存储方式。
7. 互联网的兴起，网页上要显示各种字符，必须统一啊，亲。utf-8就是Unicode最重要的实现方式之一。另外还有utf-16、utf-32等。**UTF-8不是固定字长编码的，而是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。** 这是种比较巧妙的设计，如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。
8. 注意unicode的字符编码和utf-8的存储编码表示是不同的，例如”严”字的Unicode码是4E25，UTF-8编码是E4B8A5，这个7里面解释了的，UTF-8编码不仅考虑了编码，还考虑了存储，E4B8A5是在存储识别编码的基础上塞进了4E25。
9. UTF-8 使用一至四个字节为每个字符编码。128 个 ASCII 字符（Unicode 范围由 U+0000 至 U+007F）只需一个字节，带有变音符号的拉丁文、希腊文、西里尔字母、亚美尼亚语、希伯来文、阿拉伯文、叙利亚文及马尔代夫语（Unicode 范围由 U+0080 至 U+07FF）需要二个字节，其他基本多文种平面（BMP）中的字符（CJK属于此类-Qieqie注）使用三个字节，其他 Unicode 辅助平面的字符使用四字节编码。
10. 最后，要回答你的问题，常规来看，中文汉字在utf-8中到底占几个字节，一般是3个字节，最常见的编码方式是1110xxxx 10xxxxxx 10xxxxxx。 



### Unicode

正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。

可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，就像它的名字都表示的，这是一种所有符号的编码。

Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，`U+0639`表示阿拉伯字母`Ain`，`U+0041`表示英语的大写字母`A`，`U+4E25`表示汉字`严`。具体的符号对应表，可以查询[unicode.org](http://www.unicode.org/)，或者专门的[汉字对应表](http://www.chi2ko.com/tool/CJK.htm)。

### Unicode 的问题

需要注意的是，**Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储**。

比如，汉字`严`的 Unicode 是十六进制数`4E25`，转换成二进制数足足有15位（`100111000100101`），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。

这里就有两个严重的问题，第一个问题是，如何才能区别 Unicode 和 ASCII ？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是`0`，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。

它们造成的结果是：

  1）出现了 Unicode 的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示 Unicode。

  2）Unicode 在很长一段时间内无法推广，直到互联网的出现。

### UTF-8

互联网的普及，强烈要求出现一种统一的编码方式。UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，**UTF-8 是 Unicode 的实现方式之一**。

UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

UTF-8 的编码规则很简单，只有二条：

> 1）对于单字节的符号，字节的第一位设为`0`，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。
>
> 2）对于`n`字节的符号（`n > 1`），第一个字节的前`n`位都设为`1`，第`n + 1`位设为`0`，后面字节的前两位一律设为`10`。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。

下表总结了编码规则，字母`x`表示可用编码的位。

    Unicode符号范围       |        UTF-8编码方式
    (十六进制)            |       （二进制）
    --------------------|---------------------------------------------
    0000 0000-0000 007F | 0xxxxxxx
    0000 0080-0000 07FF | 110xxxxx 10xxxxxx
    0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx
    0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx


跟据上表，解读 UTF-8 编码非常简单。如果一个字节的第一位是`0`，则这个字节单独就是一个字符；如果第一位是`1`，则连续有多少个`1`，就表示当前字符占用多少个字节。

下面，还是以汉字`严`为例，演示如何实现 UTF-8 编码。

`严`的 Unicode 是`4E25`（`100111000100101`），根据上表，可以发现`4E25`处在第三行的范围内（`0000 0800 - 0000 FFFF`），因此严的 UTF-8 编码需要三个字节，即格式是`1110xxxx 10xxxxxx 10xxxxxx`。然后，从`严`的最后一个二进制位开始，依次从后向前填入格式中的`x`，多出的位补`0`。这样就得到了，`严`的 UTF-8 编码是`11100100 10111000 10100101`，转换成十六进制就是`E4B8A5`。


### Emoji 和 字符编码

[谈谈 Emoji 和字符编码](https://zhuanlan.zhihu.com/p/25707494)